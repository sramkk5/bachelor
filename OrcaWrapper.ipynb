{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import re\n",
    "import tempfile\n",
    "import ruamel.yaml\n",
    "from ruamel.yaml.scalarstring import DoubleQuotedScalarString\n",
    "import time\n",
    "import pickle\n",
    "from modules.k8s.config import Config\n",
    "import modules.k8s.k8s_utils as k8s_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrcaWrapper:\n",
    "    \"\"\"\n",
    "    A wrapper class to run ORCA jobs on a Kubernetes cluster using a PVC for storage.\n",
    "    \"\"\"\n",
    "    def __init__(self, number_of_cores, memory_size, workdir=None, pvc=None, image='orca_image:latest', parallel=False):\n",
    "        \"\"\"\n",
    "        Initialize the OrcaWrapper instance.\n",
    "\n",
    "        :param int number_of_cores: Number of CPU cores to allocate.\n",
    "        :param int memory_size: Amount of memory to allocate in GiB.\n",
    "        :param str workdir: Working directory within the container.\n",
    "        :param str pvc: Name of the Persistent Volume Claim (PVC) to use for storage.\n",
    "        :param str image: Docker image to use for the ORCA job.\n",
    "        :param bool parallel: Whether to run the job in parallel.\n",
    "        \"\"\"\n",
    "        self.number_of_cores = number_of_cores\n",
    "        self.memory_size = memory_size\n",
    "        self.image = image\n",
    "        self.parallel = parallel\n",
    "        # self.pvc = f'claim-{os.environ[\"JUPYTERHUB_USER\"]}
    "        # if len(self.pvc) == 0:
    "        #    raise Exception("Error setting pvc, probably problem in setting env variable of actual container")\n",
    "\n",
    "        # Heuristics to find PVC and workdir if not provided\n",
    "        if pvc is None:\n",
    "            vol, _, _, _, _, mnt = os.popen('df .').readlines()[1].split()\n",
    "            pvcid = re.search('pvc-[0-9a-z-]+', vol).group(0)\n",
    "            pvc = os.popen(f'kubectl get pvc | grep {pvcid} | cut -f1 -d\" \"').read().rstrip()\n",
    "\n",
    "            if workdir is None:\n",
    "                workdir = os.path.relpath(os.getcwd(), mnt)\n",
    "\n",
    "        if workdir is None:\n",
    "            workdir = ''\n",
    "\n",
    "        self.workdir = workdir\n",
    "        self.pvc = pvc\n",
    "        self.jobname = \"orca-\" + str(uuid.uuid4())\n",
    "\n",
    "    def prehook(self, gpus=0, gputype='mig-1g.10gb', retry=1):\n",
    "        \"\"\"\n",
    "        Prepare and submit the Kubernetes job configuration.\n",
    "\n",
    "        :param int gpus: Number of GPUs to allocate.\n",
    "        :param str gputype: Type of GPU to allocate.\n",
    "        :param int retry: Number of retries for waiting the pod to be ready.\n",
    "\n",
    "        :raises ValueError: If number_of_cores is less than or equal to 0.\n",
    "        \"\"\"\n",
    "        if self.number_of_cores <= 0:\n",
    "            raise ValueError(\"Number of cores must be greater than 0.\")\n",
    "        if self.number_of_cores > 12:\n",
    "            self.number_of_cores = 12\n",
    "  \n",
    "        job = f\"\"\"\\\n",
    "apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: {self.jobname}\n",
    "spec:\n",
    "  backoffLimit: 0\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        job: {self.jobname}\n",
    "    spec:\n",
    "      restartPolicy: Never\n",
    "      containers:\n",
    "      - name: {self.jobname}\n",
    "        image: {self.image}\n",
    "        workingDir: /mnt/{self.workdir}\n",
    "        command: \n",
    "        - sleep\n",
    "        - 365d\n",
    "        securityContext:\n",
    "          runAsUser: 1000\n",
    "          runAsGroup: 1000\n",
    "          runAsNonRoot: true\n",
    "          seccompProfile:\n",
    "            type: RuntimeDefault\n",
    "          allowPrivilegeEscalation: false\n",
    "          capabilities:\n",
    "            drop:\n",
    "            - ALL\n",
    "        env:\n",
    "        - name: 'OMP_NUM_THREADS'\n",
    "          value: '{self.number_of_cores}'\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: '{self.number_of_cores}'\n",
    "            memory: {self.memory_size}Gi\n",
    "            nvidia.com/{gputype}: {gpus}\n",
    "          limits:\n",
    "            cpu: '{self.number_of_cores}'\n",
    "            memory: {self.memory_size}Gi\n",
    "            nvidia.com/{gputype}: {gpus}\n",
    "        volumeMounts:\n",
    "        - name: vol-1\n",
    "          mountPath: /mnt\n",
    "      volumes:\n",
    "      - name: vol-1\n",
    "        persistentVolumeClaim:\n",
    "          claimName: {self.pvc}\n",
    "\"\"\"\n",
    "        with tempfile.NamedTemporaryFile('w+') as y:\n",
    "            y.write(job)\n",
    "            y.flush()\n",
    "            os.system(f'kubectl apply -f {y.name}')\n",
    "            for _ in range(retry):\n",
    "                os.system(f'kubectl wait --for=condition=ready pod -l job={self.jobname}')\n",
    "\n",
    "    def posthook(self):\n",
    "        \"\"\"\n",
    "        Delete the Kubernetes job after completion.\n",
    "        \"\"\"\n",
    "        os.system(f'kubectl delete job/{self.jobname}')\n",
    "\n",
    "    def commandline(self, *args):\n",
    "        \"\"\"\n",
    "        Construct the command to execute within the Kubernetes job's pod.\n",
    "\n",
    "        :param args: Additional arguments for the command.\n",
    "        :return: The complete command to be executed (list).\n",
    "        \"\"\"\n",
    "        return ['kubectl', 'exec', '-ti', f'job/{self.jobname}', '--'] + list(args)\n",
    "\n",
    "    def run(self, orca_method, log):\n",
    "        \"\"\"\n",
    "        Run the ORCA job.\n",
    "\n",
    "        :param str orca_method: The ORCA method to execute.\n",
    "        :param str log: Log file to capture ORCA output.\n",
    "        \"\"\"\n",
    "        self.prehook()\n",
    "\n",
    "        orca_command = f\"mkdir -p /tmp/orca && cp /share/{self.workdir}/* /tmp/orca && cd /tmp/orca && /opt/orca/orca {orca_method} > {log}; cp /tmp/orca/* /share/{self.workdir}\"\n",
    "\n",
    "        kubernetes_config, label = self._write_template(orca_command)\n",
    "        print(k8s_utils.run_job(kubernetes_config, label, self.parallel))\n",
    "        \n",
    "        self.posthook()\n",
    "\n",
    "    def _write_template(self, command):\n",
    "        \"\"\"\n",
    "        Generate the Kubernetes configuration YAML file for the ORCA job.\n",
    "\n",
    "        :param str command: The command to be run inside the container.\n",
    "        :return: The name of the generated YAML file and the job identifier (tuple).\n",
    "        \"\"\"\n",
    "        timestamp = str(time.time()).replace(\".\", \"\")\n",
    "        template_file = \"orca-k8s-template.yaml\"\n",
    "        \n",
    "        with open(template_file) as ifile:\n",
    "            doc = ruamel.yaml.round_trip_load(ifile, preserve_quotes=True)\n",
    "\n",
    "            doc['spec']['template']['spec']['containers'][0]['resources']['requests']['cpu'] = self.number_of_cores\n",
    "            identificator = f\"orca-orca-rdtscp-{timestamp}\"\n",
    "            doc['metadata']['name'] = identificator\n",
    "            doc['spec']['template']['spec']['containers'][0]['name'] = f\"orca-deployment-{timestamp}\"\n",
    "            doc['spec']['template']['metadata']['labels']['app'] = identificator\n",
    "            doc['spec']['template']['spec']['containers'][0]['args'] = [\"/bin/bash\", \"-c\", DoubleQuotedScalarString(command)]\n",
    "            doc['spec']['template']['spec']['containers'][0]['image'] = self.image\n",
    "            doc['spec']['template']['spec']['containers'][0]['workingDir'] = \"/tmp/\"\n",
    "            if self.workdir:\n",
    "                doc['spec']['template']['spec']['containers'][0]['workingDir'] += self.workdir\n",
    "            doc['spec']['template']['spec']['volumes'][0]['persistentVolumeClaim']['claimName'] = self.pvc\n",
    "\n",
    "            if self.parallel:\n",
    "                with open(f\"{Config.PICKLE_PATH}/lock.pkl\", \"rb\") as fp:\n",
    "                    lock_object = pickle.load(fp)\n",
    "                if len(lock_object['Parallel_label']) == 0:\n",
    "                    label = {\"Parallel_label\": identificator, \"Count\": 0}\n",
    "                    with open(f\"{Config.PICKLE_PATH}/lock.pkl\", \"wb\") as fp:\n",
    "                        pickle.dump(label, fp)\n",
    "                else:\n",
    "                    doc['spec']['template']['metadata']['labels']['app'] = lock_object['Parallel_label']\n",
    "            \n",
    "            ofile_name = f\"orca-rdtscp.yaml\"\n",
    "            with open(ofile_name, \"w\") as ofile:\n",
    "                ruamel.yaml.round_trip_dump(doc, ofile, explicit_start=True)\n",
    "            \n",
    "            return ofile_name, identificator"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
