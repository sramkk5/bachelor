{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import pickle\n",
    "import ruamel.yaml\n",
    "from ruamel.yaml.scalarstring import DoubleQuotedScalarString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrcaWrapper:\n",
    "    def __init__(self, orca_path='orca'):\n",
    "        \"\"\"\n",
    "        Initialize the OrcaWrapper with the path to the ORCA executable.\n",
    "\n",
    "        :param str orca_path: Path to the ORCA executable.\n",
    "        \"\"\"\n",
    "        self.orca_path = orca_path\n",
    "\n",
    "    def setup_calculation(self, method, command, params):\n",
    "        \"\"\"\n",
    "        Set up the ORCA calculation by customizing a Kubernetes template.\n",
    "\n",
    "        :param str method: Method used for the calculation.\n",
    "        :param str command: Command to execute the ORCA calculation.\n",
    "        :param dict params: Additional parameters for customizing the template.\n",
    "\n",
    "        :return: Filename of the Kubernetes configuration file as a string.\n",
    "        :return: Identifier for the ORCA calculation as a string.\n",
    "        \"\"\"\n",
    "        orca_method_file = params.get('orca_method_file', '')\n",
    "        timestamp = str(time.time()).replace(\".\", \"\")\n",
    "        method = method.replace(\"_\", \"-\")\n",
    "\n",
    "        # Determine default image and name based on the method\n",
    "        default_image, default_name = self._get_default_image_and_name(method, params)\n",
    "\n",
    "        # Load Kubernetes template from file\n",
    "        template_file = \"orca-k8s-template.yaml\" if method == \"orca\" else \"gmx-k8s-template.yaml\"\n",
    "        with open(template_file) as ifile:\n",
    "            doc = ruamel.yaml.round_trip_load(ifile, preserve_quotes=True)\n",
    "\n",
    "            # Customize the template with parameters and settings\n",
    "            self._customize_template(doc, method, command, params, default_image, default_name)\n",
    "\n",
    "            # Generate an identifier for the ORCA calculation\n",
    "            identificator = \"{}-{}-rdtscp-{}\".format(default_name, method, timestamp)\n",
    "\n",
    "            # Write the customized template to a YAML file\n",
    "            ofile_name = \"{}-{}-rdtscp.yaml\".format(default_name, method)\n",
    "            with open(ofile_name, \"w\") as ofile:\n",
    "                ruamel.yaml.round_trip_dump(doc, ofile, explicit_start=True)\n",
    "\n",
    "            return ofile_name, identificator\n",
    "\n",
    "    def run_calculation(self, method, orca_method, log, **kwargs):\n",
    "        \"\"\"\n",
    "        Run the ORCA calculation by setting up Kubernetes job and executing it.\n",
    "\n",
    "        :param str method: Method used for the calculation.\n",
    "        :param str orca_method: ORCA method used for the computation.\n",
    "        :param str log: Log file to store the output of the calculation.\n",
    "        :kwargs: Additional parameters for customizing the calculation.\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"image\": kwargs.get('image', None),\n",
    "            \"workdir\": kwargs.get('workdir', None),\n",
    "            \"parallel\": kwargs.get('parallel', None)\n",
    "        }\n",
    "\n",
    "        # Prepare ORCA command to execute the calculation\n",
    "        orca_command = self._prepare_orca_command(orca_method, log, params)\n",
    "\n",
    "        # Set up the calculation and run the Kubernetes job\n",
    "        method_path = \"{}/{}\".format(params['workdir'], orca_method)\n",
    "        kubernetes_config, label = self.setup_calculation(method, orca_command, params)\n",
    "        print(self._run_job(kubernetes_config, label, params[\"parallel\"]))\n",
    "\n",
    "    def _get_default_image_and_name(self, method, params):\n",
    "        \"\"\"\n",
    "        Determine the default Docker image and name based on the method.\n",
    "        \n",
    "        :param str method: Method used for the calculation.\n",
    "        :param dict params: Additional parameters for customizing the calculation.\n",
    "        :return: Default Docker image as a string.\n",
    "        :return: Default name as a string.\n",
    "        \"\"\"\n",
    "        if method == \"orca\":\n",
    "            return 'ljocha/orca:5.0.1', 'orca'\n",
    "        elif method == 'parmtsnecv':\n",
    "            return Config.PARMTSNECV_IMAGE, 'parmtsnecv'\n",
    "        else:\n",
    "            return Config.GMX_IMAGE, 'gromacs'\n",
    "\n",
    "    def _customize_template(self, doc, method, command, params, default_image, default_name):\n",
    "        \"\"\"\n",
    "        Customize the Kubernetes template with parameters and settings.\n",
    "\n",
    "        :param dict doc: Kubernetes template document.\n",
    "        :param str method: Method used for the calculation.\n",
    "        :param str command: Command to execute the calculation.\n",
    "        :param dict params: Additional parameters for customizing the template.\n",
    "        :param str default_image: Default Docker image.\n",
    "        :param str default_name: Default name.\n",
    "        \"\"\"\n",
    "        doc['spec']['template']['spec']['containers'][0]['image'] = default_image if not params[\"image\"] else params[\"image\"]\n",
    "        doc['spec']['template']['spec']['containers'][0]['workingDir'] = \"/tmp/\"\n",
    "        if params[\"workdir\"]:\n",
    "            doc['spec']['template']['spec']['containers'][0]['workingDir'] += params[\"workdir\"]\n",
    "\n",
    "    def _prepare_orca_command(self, orca_method, log, params):\n",
    "        \"\"\"\n",
    "        Prepare the ORCA command for execution in the Kubernetes cluster.\n",
    "        \n",
    "        :param str orca_method: ORCA method used for the computation.\n",
    "        :param str log: Log file to store the output of the computation.\n",
    "        :param dict params: Dictionary containing additional parameters for the computation,\n",
    "                            such as the working directory and parallel flag.\n",
    "        :return: The prepared ORCA command as a string.\n",
    "        \"\"\"\n",
    "        # Define the ORCA application and construct the command string\n",
    "        application = \"orca\"\n",
    "        orca_command = (\n",
    "            f\"mkdir -p /tmp/orca && \"\n",
    "            f\"cp /share/{params['workdir']}/* /tmp/orca && \"\n",
    "            f\"cd /tmp/orca && \"\n",
    "            f\"/opt/orca/{application} {orca_method} > {log}; \"\n",
    "            f\"cp /tmp/orca/* /share/{params['workdir']}\"\n",
    "        )\n",
    "        return orca_command\n",
    "\n",
    "    def _run_job(self, kubernetes_config, label, parallel):\n",
    "        \"\"\"\n",
    "        Run the Kubernetes job for executing the ORCA computation.\n",
    "\n",
    "        :param str kubernetes_config: The Kubernetes configuration file for the job.\n",
    "        :param str label: The label for identifying the job.\n",
    "        :param bool parallel: Flag indicating whether parallel execution is enabled.\n",
    "        \"\"\"\n",
    "        # Check if parallel execution is enabled\n",
    "        if parallel:\n",
    "            # If parallel execution is enabled, modify the label to include the parallel identifier\n",
    "            label += \"-parallel\"\n",
    "    \n",
    "        # Execute the Kubernetes job using kubectl\n",
    "        try:\n",
    "            # Example command: kubectl apply -f kubernetes_config.yaml --selector app=label\n",
    "            subprocess.run([\"kubectl\", \"apply\", \"-f\", kubernetes_config, \"--selector\", f\"app={label}\"], check=True)\n",
    "            print(\"Kubernetes job submitted successfully.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error submitting Kubernetes job: {e}\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import tempfile\n",
    "\n",
    "class OrcaRunnerK8s:\n",
    "    orca_cmd = 'orca'\n",
    "\n",
    "    def __init__(self, pvc=None, workdir=None, image='ljocha/orca:5.0.1', **kwargs):\n",
    "        self.image = image\n",
    "\n",
    "        # Heuristics to find PVC and working dir\n",
    "        if pvc is None:\n",
    "            vol, _, _, _, _, mnt = os.popen('df .').readlines()[1].split()\n",
    "            pvcid = re.search('pvc-[0-9a-z-]+', vol).group(0)\n",
    "            pvc = os.popen(f'kubectl get pvc | grep {pvcid} | cut -f1 -d\" \"').read().rstrip()\n",
    "\n",
    "        if workdir is None:\n",
    "            workdir = os.path.relpath(os.getcwd(), mnt)\n",
    "\n",
    "        self.workdir = workdir\n",
    "        self.pvc = pvc\n",
    "        self.jobname = \"orca-\" + str(uuid.uuid4())\n",
    "\n",
    "    def prehook(self, cores=None, mpi=1, omp=1, gpus=0, gputype='mig-1g.10gb', mem=4):\n",
    "        # Logic to generate Kubernetes Job YAML configuration\n",
    "        job_yaml = \"\"\"\n",
    "apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: {jobname}\n",
    "spec:\n",
    "  backoffLimit: 0\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        job: {jobname}\n",
    "    spec:\n",
    "      restartPolicy: Never\n",
    "      containers:\n",
    "      - name: {jobname}\n",
    "        image: {image}\n",
    "        workingDir: /mnt/{workdir}\n",
    "        command: \n",
    "        - sleep\n",
    "        - 365d\n",
    "        # Add security context, resources, volume mounts, etc.\n",
    "      volumes:\n",
    "      - name: vol-1\n",
    "        persistentVolumeClaim:\n",
    "          claimName: {pvc}\n",
    "\"\"\".format(jobname=self.jobname, image=self.image, workdir=self.workdir, pvc=self.pvc)\n",
    "\n",
    "        # Apply Kubernetes Job configuration\n",
    "        with tempfile.NamedTemporaryFile('w+') as y:\n",
    "            y.write(job_yaml)\n",
    "            y.flush()\n",
    "            os.system(f'kubectl apply -f {y.name}')\n",
    "            os.system(f'kubectl wait --for=condition=ready pod -l job={self.jobname}')\n",
    "\n",
    "    def posthook(self):\n",
    "        # Cleanup Kubernetes Job\n",
    "        os.system(f'kubectl delete job/{self.jobname}')\n",
    "\n",
    "    def commandline(self, **kwargs):\n",
    "        # Return the command line to execute commands in the Kubernetes pod\n",
    "        return ['kubectl', 'exec', '-ti', f'job/{self.jobname}', '--', self.orca_cmd]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
